version: '3.9'



services:

  # Apache-Spark
  spark-master:
    build: 
      context: ./
      dockerfile: ./Dockerfile
    container_name: spark-master
    hostname: spark_master
    environment:
      - SPARK_MODE=master
      - SPARK_LOCAL_IP=spark-master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
    volumes:
      - ./data_spark:/opt/spark-data
      - ./config/spark-defaults.conf:/opt/bitnami/spark/config/spark-defaults.conf
      - ./data:/opt/spark
    expose:
      - "7077"
    ports:
      - "7077:7077"
      - "8080:8080"
    networks:
      - spark_network

  spark-worker:
    image: docker.io/bitnami/spark:3.3.2
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    deploy: 
      replicas: 3
    depends_on: 
      - spark-master
    volumes:
      - ./data_spark:/opt/spark-data
    networks:
      - spark_network


  # # MinIO
  # minio:
  #   hostname: minio
  #   image: minio/minio
  #   container_name: minio
  #   ports:
  #     - 9001:9001
  #     - 9000:9000
  #   command: [ "server", "/data", "--console-address", ":9001" ]
  #   volumes:
  #     - ./minio:/data
  #   env_file: .env
  #   networks:
  #     - spark_network

  # mc:
  #   image: minio/mc
  #   container_name: mc
  #   hostname: mc
  #   env_file: .env
  #   entrypoint: >
  #     /bin/sh -c " until (/usr/bin/mc config host add minio
  #     http://minio:9000 minio minio123) do echo '...waiting...' && sleep 1;
  #     done; /usr/bin/mc mb minio/lakehouse; /usr/bin/mc policy set public
  #     minio/lakehouse; exit 0; "
  #   depends_on:
  #     - minio
  #   networks:
  #     - spark_network


  # Jupyter-Notebook
  # spark-notebook:
  #   image: jupyter/pyspark-notebook
  #   container_name: spark-notebook
  #   # command: [ "start-notebook.sh", "--NotebookApp.token=" ]
  #   ports:
  #     - 8888:8888
  #   volumes:
  #     - ./notebooks:/home/jovyan/work
  #     - ./data:/home/jovyan/data
  #   environment:
  #     - JUPYTER_ENABLE_LAB=yes
  #     - GRANT_SUDO=yes
  #   networks:
  #     - spark_network


networks:
  spark_network:
    driver: bridge
    name: spark_network